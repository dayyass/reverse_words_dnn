{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from typing import Counter as CounterType, Dict, List, Tuple\n",
    "\n",
    "import torch\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preapre Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        path_to_data: str,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.path_to_data = path_to_data\n",
    "        self.dataset = self._prepare_dataset(path_to_data)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(\n",
    "        self,\n",
    "        idx: int,\n",
    "    ) -> List[str]:\n",
    "        return self.dataset[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def _prepare_dataset(path_to_data: str) -> List[List[str]]:\n",
    "        dataset = []\n",
    "\n",
    "        pos_dir = os.path.join(path_to_data, \"pos\")\n",
    "        neg_dir = os.path.join(path_to_data, \"neg\")\n",
    "        \n",
    "        for dir in [pos_dir, neg_dir]:\n",
    "            for filename in tqdm(\n",
    "                os.listdir(dir),\n",
    "                desc=\"parse txt files\",\n",
    "            ):\n",
    "                if not filename.endswith(\".txt\"):\n",
    "                    continue\n",
    "                with open(os.path.join(dir, filename), mode=\"r\") as fp:\n",
    "                    review = fp.read()\n",
    "                    dataset.append(word_tokenize(review.lower()))\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:36<00:00, 342.36it/s]\n",
      "100%|██████████| 12500/12500 [00:33<00:00, 368.81it/s]\n",
      "100%|██████████| 12500/12500 [00:34<00:00, 359.97it/s]\n",
      "100%|██████████| 12500/12500 [00:38<00:00, 328.76it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = IMDBDataset(path_to_data=\"data/aclImdb/train\")\n",
    "test_dataset = IMDBDataset(path_to_data=\"data/aclImdb/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['for',\n",
       " 'a',\n",
       " 'movie',\n",
       " 'that',\n",
       " 'gets',\n",
       " 'no',\n",
       " 'respect',\n",
       " 'there',\n",
       " 'sure',\n",
       " 'are',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'memorable',\n",
       " 'quotes',\n",
       " 'listed',\n",
       " 'for',\n",
       " 'this',\n",
       " 'gem',\n",
       " '.',\n",
       " 'imagine',\n",
       " 'a',\n",
       " 'movie',\n",
       " 'where',\n",
       " 'joe',\n",
       " 'piscopo',\n",
       " 'is',\n",
       " 'actually',\n",
       " 'funny',\n",
       " '!',\n",
       " 'maureen',\n",
       " 'stapleton',\n",
       " 'is',\n",
       " 'a',\n",
       " 'scene',\n",
       " 'stealer',\n",
       " '.',\n",
       " 'the',\n",
       " 'moroni',\n",
       " 'character',\n",
       " 'is',\n",
       " 'an',\n",
       " 'absolute',\n",
       " 'scream',\n",
       " '.',\n",
       " 'watch',\n",
       " 'for',\n",
       " 'alan',\n",
       " '``',\n",
       " 'the',\n",
       " 'skipper',\n",
       " \"''\",\n",
       " 'hale',\n",
       " 'jr.',\n",
       " 'as',\n",
       " 'a',\n",
       " 'police',\n",
       " 'sgt',\n",
       " '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_len_distr = [len(review) for review in train_dataset]\n",
    "test_dataset_len_distr = [len(review) for review in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(\n",
    "    train_dataset_len_distr,\n",
    "    bins=len(set(train_dataset_len_distr)),\n",
    "    alpha=0.5,\n",
    "    label=\"train\",\n",
    ")\n",
    "plt.hist(\n",
    "    test_dataset_len_distr,\n",
    "    bins=len(set(test_dataset_len_distr)),\n",
    "    alpha=0.5,\n",
    "    label=\"test\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.title(\"Review's length distribution\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 22482), (2, 2132), (4, 386)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_n_digits_distr = Counter([len(str(length)) for length in train_dataset_len_distr])\n",
    "train_dataset_n_digits_distr.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 22372), (2, 2262), (4, 363), (1, 3)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_n_digits_distr = Counter([len(str(length)) for length in test_dataset_len_distr])\n",
    "test_dataset_n_digits_distr.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_counter = Counter()\n",
    "\n",
    "for review in train_dataset:\n",
    "    tokens_counter.update(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111836,\n",
       " [('the', 334840),\n",
       "  (',', 275887),\n",
       "  ('.', 234757),\n",
       "  ('and', 163477),\n",
       "  ('a', 162292)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_counter), tokens_counter.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token2Idx:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        tokens_counter: CounterType,\n",
    "        min_df: int,\n",
    "    ):\n",
    "        self.tokens_counter = tokens_counter\n",
    "        self.min_df = min_df\n",
    "\n",
    "        self.token2idx = self._prepare_token2idx(\n",
    "            tokens_counter=tokens_counter,\n",
    "            min_df=min_df,\n",
    "        )\n",
    "    \n",
    "    def __call__(\n",
    "        self,\n",
    "        seq: List[str],\n",
    "    ) -> torch.LongTensor:\n",
    "        return [self.token2idx.get(token, self.token2idx[\"<unk>\"]) for token in seq]\n",
    "    \n",
    "    def __getitem__(self, key: str) -> int:\n",
    "        return self.token2idx[key]\n",
    "\n",
    "    @staticmethod\n",
    "    def _prepare_token2idx(\n",
    "        tokens_counter: CounterType,\n",
    "        min_df: int,\n",
    "    ) -> Dict[str, int]:\n",
    "        token2idx = {\n",
    "            \"<bos>\": 0,\n",
    "            \"<eos>\": 1,\n",
    "            \"<unk>\": 2,\n",
    "            \"<pad>\": 3,\n",
    "        }\n",
    "\n",
    "        for token, cnt in tqdm(\n",
    "            tokens_counter.most_common(),\n",
    "            desc=\"loop over unique tokens\",\n",
    "        ):\n",
    "            if token in token2idx:\n",
    "                continue\n",
    "            if cnt < min_df:\n",
    "                continue\n",
    "\n",
    "            token2idx[token] = len(token2idx)\n",
    "        \n",
    "        return token2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over unique tokens: 100%|██████████| 111836/111836 [00:00<00:00, 1272351.97it/s]\n"
     ]
    }
   ],
   "source": [
    "token2idx = Token2Idx(\n",
    "    tokens_counter=tokens_counter,\n",
    "    min_df=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31577"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token2idx.token2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24,\n",
       " 8,\n",
       " 26,\n",
       " 20,\n",
       " 225,\n",
       " 73,\n",
       " 1174,\n",
       " 53,\n",
       " 263,\n",
       " 37,\n",
       " 8,\n",
       " 190,\n",
       " 9,\n",
       " 901,\n",
       " 4357,\n",
       " 3517,\n",
       " 24,\n",
       " 19,\n",
       " 1520,\n",
       " 6,\n",
       " 828,\n",
       " 8,\n",
       " 26,\n",
       " 134,\n",
       " 874,\n",
       " 14565,\n",
       " 11,\n",
       " 177,\n",
       " 182,\n",
       " 43,\n",
       " 7162,\n",
       " 15090,\n",
       " 11,\n",
       " 8,\n",
       " 156,\n",
       " 18872,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 124,\n",
       " 11,\n",
       " 48,\n",
       " 1512,\n",
       " 2013,\n",
       " 6,\n",
       " 125,\n",
       " 24,\n",
       " 1526,\n",
       " 35,\n",
       " 4,\n",
       " 18873,\n",
       " 34,\n",
       " 8602,\n",
       " 2130,\n",
       " 23,\n",
       " 8,\n",
       " 565,\n",
       " 6964,\n",
       " 6]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2idx(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "assertion loop: 100%|██████████| 25000/25000 [00:02<00:00, 8689.90it/s] \n",
      "assertion loop: 100%|██████████| 25000/25000 [00:03<00:00, 8208.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for dataset in [train_dataset, test_dataset]:\n",
    "    for review in tqdm(\n",
    "        dataset,\n",
    "        desc=\"assertion loop\",\n",
    "    ):\n",
    "        assert len(review) == len(token2idx(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collator:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        token2idx: Token2Idx,\n",
    "    ):\n",
    "        self.token2idx = token2idx\n",
    "    \n",
    "    def __call__(\n",
    "        self,\n",
    "        batch: List[List[str]],\n",
    "    ) -> torch.LongTensor:\n",
    "        tensor_seq = []\n",
    "        tensor_inv_seq = []\n",
    "        for seq in batch:\n",
    "            tokenized_seq = self.token2idx(seq)\n",
    "            tensor_seq.append(torch.LongTensor(tokenized_seq))\n",
    "\n",
    "            tokenized_inv_seq = [self.token2idx[\"<bos>\"]] + tokenized_seq[::-1] + [self.token2idx[\"<eos>\"]]\n",
    "            tensor_inv_seq.append(torch.LongTensor(tokenized_inv_seq))\n",
    "\n",
    "        padded_sequences =  torch.nn.utils.rnn.pad_sequence(\n",
    "            sequences=tensor_seq,\n",
    "            batch_first=True,\n",
    "            padding_value=self.token2idx[\"<pad>\"],\n",
    "        )\n",
    "        padded_inv_sequences =  torch.nn.utils.rnn.pad_sequence(\n",
    "            sequences=tensor_inv_seq,\n",
    "            batch_first=True,\n",
    "            padding_value=self.token2idx[\"<pad>\"],\n",
    "        )\n",
    "        return padded_sequences, padded_inv_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = Collator(token2idx=token2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=2,  # TODO\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=collator,\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 243]), torch.Size([2, 245]))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq, inv_seq = next(iter(train_dataloader))\n",
    "seq.shape, inv_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 283]), torch.Size([1, 285]))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq, inv_seq = next(iter(test_dataloader))\n",
    "seq.shape, inv_seq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_parameters(model: torch.nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqLSTM(torch.nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        num_embeddings: int,\n",
    "        embedding_dim: int,\n",
    "        encoder_hidden_size: int,\n",
    "        encoder_num_layers: int,  # TODO: fix if > 1\n",
    "        encoder_dropout: float,\n",
    "        encoder_bidirectional: bool,\n",
    "        decoder_num_layers: int,  # TODO: fix if > 1\n",
    "        decoder_dropout: float,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(\n",
    "            num_embeddings=num_embeddings,\n",
    "            embedding_dim=embedding_dim,\n",
    "            padding_idx=token2idx[\"<pad>\"], # TODO: remove hardcode\n",
    "\n",
    "        )\n",
    "        self.encoder = torch.nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=encoder_hidden_size,\n",
    "            num_layers=encoder_num_layers,\n",
    "            dropout=encoder_dropout,\n",
    "            bidirectional=encoder_bidirectional,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        decoder_hidden_size = encoder_hidden_size * (2 if encoder_bidirectional else 1)\n",
    "        self.decoder = torch.nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=decoder_hidden_size,\n",
    "            num_layers=decoder_num_layers,\n",
    "            dropout=decoder_dropout,\n",
    "            bidirectional=False,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.head = torch.nn.Linear(\n",
    "            in_features=decoder_hidden_size,\n",
    "            out_features=num_embeddings,\n",
    "        )\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        seq: torch.LongTensor,\n",
    "        inv_seq: torch.LongTensor,\n",
    "    ):\n",
    "        emb = self._embed(seq)\n",
    "        encoder_output, _ = self.encoder(emb)\n",
    "        skip_thoughts = self._get_skip_thoughts(encoder_output=encoder_output)\n",
    "\n",
    "        inv_emb = self._embed(inv_seq)\n",
    "        decoder_output, _ = self.decoder(inv_emb, (skip_thoughts, skip_thoughts))\n",
    "\n",
    "        decoder_output, _ = self._pad_packed_sequence(sequence=decoder_output)\n",
    "        logits = self.head(decoder_output)\n",
    "        return logits\n",
    "    \n",
    "    def _embed(\n",
    "        self,\n",
    "        seq: torch.LongTensor,\n",
    "    ) -> torch.nn.utils.rnn.PackedSequence:\n",
    "        emb = self.embedding(seq)\n",
    "        lengths = (seq != token2idx[\"<pad>\"]).sum(dim=1) # TODO: remove hardcode\n",
    "        return torch.nn.utils.rnn.pack_padded_sequence(\n",
    "            input=emb, lengths=lengths,\n",
    "            batch_first=True, enforce_sorted=False,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def _pad_packed_sequence(\n",
    "        sequence: torch.nn.utils.rnn.PackedSequence,\n",
    "    ) -> Tuple[torch.Tensor, torch.LongTensor]:\n",
    "        return torch.nn.utils.rnn.pad_packed_sequence(\n",
    "            sequence=sequence,\n",
    "            batch_first=True,\n",
    "            padding_value=token2idx[\"<pad>\"], # TODO: remove hardcode\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_skip_thoughts(\n",
    "        encoder_output: torch.nn.utils.rnn.PackedSequence,\n",
    "    ) -> torch.Tensor:\n",
    "        encoder_output, lengths = Seq2SeqLSTM._pad_packed_sequence(sequence=encoder_output)\n",
    "        return torch.index_select(\n",
    "            input=encoder_output,\n",
    "            dim=1,\n",
    "            index=lengths - 1,\n",
    "        ).mean(dim=1).unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqLSTM(\n",
    "    num_embeddings=len(token2idx.token2idx),\n",
    "    embedding_dim=100,\n",
    "    encoder_hidden_size=128,\n",
    "    encoder_num_layers=1,\n",
    "    encoder_dropout=0,  # num_layers = 1\n",
    "    encoder_bidirectional=True,\n",
    "    decoder_num_layers=1,\n",
    "    decoder_dropout=0,  # num_layers = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11875101"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 181, 31577])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(*next(iter(train_dataloader))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "657357e3c76d50bb191e51ab294f4ff9fbef969f799c39920a46f2649b2b9e52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
